{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire Prediction Model\n",
    "\n",
    "The Fire Prediction Project utilizes a mix of historical fire data from the [Oregon Open Data Portal](https://data.oregon.gov/Natural-Resources/ODF-Fire-Occurrence-Data-2000-2022/fbwv-q84y/about_data) and historical hourly and daily weather data from the [Open-Meteo Historical Weather API](https://open-meteo.com/en/docs/historical-weather-api) to train a model that measures fire ignition probability under varying weather features. An iterative API call is used to gather appropriate weather data, which is married with the associated fire ignition data (indicated as class 1). Concurrently, additional weather data from dates ***not*** associated with fire ignition is retrieved (indicated as class 0). \n",
    "\\\n",
    "\\\n",
    "The model used is a Random Forest Classifier, which is tuned during each run with a GridSearchCV across multiple key hyperparameters. In its final state, weather variables are declared and input into the model to determine probability of fire ignition. In this script, the variables are declared such that fire ignition would not be probable, and the probabilistic result matches based on expectation from domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model requires weather data which is reliably associated with normal, non-fire conditions. In order to generate dates that fall outside of the Oregon fire data, a Series of dates not present in the input dataframe is generated. Later in the script, this Series will be randomly sampled against (with replacement), and the resulting dates are used for the API call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for generating random dates not present in original fire dataset.\n",
    "# To be used for weather data not associated with fires.\n",
    "\n",
    "\n",
    "def rand_date(input_df, record_length=2000):\n",
    "    minimum_date = input_df[\n",
    "        \"date\"\n",
    "    ].min()  # Initializing range of dates associated with df\n",
    "    maximum_date = input_df[\"date\"].max()\n",
    "\n",
    "    listed_date = [minimum_date]  # Initializing list of dates with minimum\n",
    "    new_dates = []\n",
    "\n",
    "    while minimum_date != maximum_date:  # All dates not associated with fires\n",
    "        minimum_date += timedelta(days=1)\n",
    "        if minimum_date in input_df[\"date\"]:\n",
    "            pass\n",
    "        else:\n",
    "            listed_date.append(minimum_date)\n",
    "\n",
    "    for i in range(\n",
    "        record_length\n",
    "    ):  # Random generation of dates not associated with fire\n",
    "        rand_num = np.random.randint(0, len(listed_date))\n",
    "        curr_date = listed_date[rand_num]\n",
    "        new_dates.append(curr_date)\n",
    "\n",
    "    return pd.Series(new_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data - Historical and API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Oregon fire datasets, it is important to clean out various null records and account for basic data anomalies. In the below, nulls are completely removed (as this only accounts for a small proportion of the data, which has an insignifant effect on the final model training). Additionally, entries where the fire was indicated to be under control (Control_DateTime) before the fire ignited (Ign_DateTime) were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After reading in data, a random sample of record_length will be retrieved.\n",
    "directory = os.getcwd()\n",
    "files = glob.glob(f\"{directory}/*.csv\")\n",
    "df_fire_full = pd.read_csv(files[0])\n",
    "record_length = 2000\n",
    "\n",
    "# Reading in fire data and dropping unnecessary columns for analysis\n",
    "df_fire_cleaned = df_fire_full.drop(\n",
    "    [\n",
    "        \"Serial\",\n",
    "        \"FireCategory\",\n",
    "        \"Area\",\n",
    "        \"DistrictName\",\n",
    "        \"UnitName\",\n",
    "        \"FullFireNumber\",\n",
    "        \"Cause_Comments\",\n",
    "        \"LatLongDD\",\n",
    "        \"FO_LandOwnType\",\n",
    "        \"Twn\",\n",
    "        \"Rng\",\n",
    "        \"Sec\",\n",
    "        \"Subdiv\",\n",
    "        \"LandmarkLocation\",\n",
    "        \"County\",\n",
    "        \"RegUseZone\",\n",
    "        \"RegUseRestriction\",\n",
    "        \"Industrial_Restriction\",\n",
    "        \"DistrictCode\",\n",
    "        \"UnitCode\",\n",
    "        \"DistFireNumber\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Pulling in most recent 2000 observations\n",
    "df_fire_cleaned.sort_values([\"ReportDateTime\"], inplace=True, ascending=False)\n",
    "df_fire_cleaned = df_fire_cleaned.sample(n=record_length)\n",
    "\n",
    "# Dropping any null rows\n",
    "df_fire_cleaned = df_fire_cleaned.dropna()\n",
    "\n",
    "# Converting datetime columns to appropriate datatype\n",
    "df_fire_cleaned[\"Ign_DateTime\"] = pd.to_datetime(\n",
    "    df_fire_cleaned[\"Ign_DateTime\"], format=\"%m/%d/%Y %I:%M:%S %p\"\n",
    ")\n",
    "df_fire_cleaned[\"Control_DateTime\"] = pd.to_datetime(\n",
    "    df_fire_cleaned[\"Control_DateTime\"], format=\"%m/%d/%Y %I:%M:%S %p\"\n",
    ")\n",
    "\n",
    "# Invalid data where the controlled datetime occured before the ignite datetime.\n",
    "df_fire_cleaned = df_fire_cleaned.drop(\n",
    "    df_fire_cleaned.index[\n",
    "        df_fire_cleaned[\"Control_DateTime\"] < df_fire_cleaned[\"Ign_DateTime\"]\n",
    "    ].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below retrieves weather data associated with the historical fire data and weather data for dates which are ***not*** present in the historical fire data. Importantly, certain variables are obtained at the hourly level, and these resulting dataframes must be rightsized for future aggregation and merging to the daily level. The end goal is combining all data at the daily level (using appropriate mean or sum aggregates) and generating a dataframe with all weather variables and an indicator (class 0 or 1) for fire ignition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1982 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1982/1982 [06:50<00:00,  4.83it/s]\n",
      "100%|██████████| 2000/2000 [06:30<00:00,  5.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession(\".cache\", expire_after=-1)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=5)\n",
    "openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "hourly_dataframe_agg = pd.DataFrame()\n",
    "daily_dataframe_agg = pd.DataFrame()\n",
    "\n",
    "for point in tqdm(range(len(df_fire_cleaned))):\n",
    "    lat_current = df_fire_cleaned[\"Lat_DD\"].iloc[point]\n",
    "    long_current = df_fire_cleaned[\"Long_DD\"].iloc[point]\n",
    "\n",
    "    # Make sure all required weather variables are listed here\n",
    "    # The order of variables in hourly or daily is important to assign them correctly below\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "    # Model is built to determine fire ignition probability - using Ign_DateTime as date param\n",
    "    params = {\n",
    "        \"latitude\": lat_current,\n",
    "        \"longitude\": long_current,\n",
    "        \"start_date\": datetime.strftime(\n",
    "            df_fire_cleaned[\"Ign_DateTime\"].iloc[point].date(), \"%Y-%m-%d\"\n",
    "        ),\n",
    "        \"end_date\": datetime.strftime(\n",
    "            df_fire_cleaned[\"Ign_DateTime\"].iloc[point].date(), \"%Y-%m-%d\"\n",
    "        ),\n",
    "        \"hourly\": [\n",
    "            \"soil_moisture_0_to_7cm\",\n",
    "            \"surface_pressure\",\n",
    "            \"dew_point_2m\",\n",
    "            \"apparent_temperature\",\n",
    "            \"precipitation\",\n",
    "        ],\n",
    "        \"daily\": [\n",
    "            \"wind_speed_10m_max\",\n",
    "            \"et0_fao_evapotranspiration\",\n",
    "            \"temperature_2m_max\",\n",
    "            \"temperature_2m_min\",\n",
    "        ],\n",
    "        \"temperature_unit\": \"fahrenheit\",\n",
    "        \"wind_speed_unit\": \"mph\",\n",
    "        \"precipitation_unit\": \"inch\",\n",
    "        \"timezone\": \"America/Los_Angeles\",\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "    response = responses[0]\n",
    "\n",
    "    # Retrieve hourly data from API. The order of variables needs to be the same as requested.\n",
    "    hourly = response.Hourly()\n",
    "    hourly_soil_moisture_0_to_7cm = hourly.Variables(0).ValuesAsNumpy()\n",
    "    hourly_surface_pressure = hourly.Variables(1).ValuesAsNumpy()\n",
    "    hourly_dew_point_2m = hourly.Variables(2).ValuesAsNumpy()\n",
    "    hourly_apparent_temperature = hourly.Variables(3).ValuesAsNumpy()\n",
    "    hourly_precipitation = hourly.Variables(4).ValuesAsNumpy()\n",
    "\n",
    "    # Initializing dictionary with appropriate dates for hourly interval data\n",
    "    # Hourly variables cut off at the end of the day of ignition\n",
    "    hourly_data = {\n",
    "        \"date\": pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True).replace(\n",
    "                hour=23, minute=59, second=59\n",
    "            ),\n",
    "            freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "            inclusive=\"left\",\n",
    "        )\n",
    "    }\n",
    "    hourly_data[\"soil_moisture_0_to_7cm\"] = hourly_soil_moisture_0_to_7cm[\n",
    "        : len(hourly_data[\"date\"])\n",
    "    ]\n",
    "    hourly_data[\"surface_pressure\"] = hourly_surface_pressure[\n",
    "        : len(hourly_data[\"date\"])\n",
    "    ]\n",
    "    hourly_data[\"dew_point_2m\"] = hourly_dew_point_2m[: len(hourly_data[\"date\"])]\n",
    "    hourly_data[\"apparent_temperature\"] = hourly_apparent_temperature[\n",
    "        : len(hourly_data[\"date\"])\n",
    "    ]\n",
    "    hourly_data[\"precipitation\"] = hourly_precipitation[: len(hourly_data[\"date\"])]\n",
    "\n",
    "    # Resizing the daily fire data by duplicating entries based on number of hourly observations\n",
    "    hourly_dataframe = pd.DataFrame(data=hourly_data)\n",
    "    df_fire_cleaned_repeat_hour = pd.DataFrame(\n",
    "        np.tile(df_fire_cleaned.iloc[point].values, (len(hourly_dataframe), 1)),\n",
    "        columns=df_fire_cleaned.columns,\n",
    "    )\n",
    "\n",
    "    # Combining the hourly weather data with the duplicated fire entries\n",
    "    hourly_dataframe = pd.concat(\n",
    "        [hourly_dataframe, df_fire_cleaned_repeat_hour], axis=1\n",
    "    )\n",
    "    hourly_dataframe_agg = pd.concat(\n",
    "        [hourly_dataframe_agg, hourly_dataframe], ignore_index=True, axis=0\n",
    "    )\n",
    "\n",
    "    # Process daily data. The order of variables needs to be the same as requested.\n",
    "    daily = response.Daily()\n",
    "    daily_wind_speed_10m_max = daily.Variables(0).ValuesAsNumpy()\n",
    "    daily_et0_fao_evapotranspiration = daily.Variables(1).ValuesAsNumpy()\n",
    "    daily_temperature_2m_max = daily.Variables(2).ValuesAsNumpy()\n",
    "    daily_temperature_2m_min = daily.Variables(3).ValuesAsNumpy()\n",
    "\n",
    "    # Initializing dictionary with appropriate dates for daily interval data\n",
    "    daily_data = {\n",
    "        \"date\": pd.date_range(\n",
    "            start=pd.to_datetime(daily.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(daily.TimeEnd(), unit=\"s\", utc=True),\n",
    "            freq=pd.Timedelta(seconds=daily.Interval()),\n",
    "            inclusive=\"left\",\n",
    "        )\n",
    "    }\n",
    "    daily_data[\"wind_speed_10m_max\"] = daily_wind_speed_10m_max\n",
    "    daily_data[\"et0_fao_evapotranspiration\"] = daily_et0_fao_evapotranspiration\n",
    "    daily_data[\"temperature_2m_max\"] = daily_temperature_2m_max\n",
    "    daily_data[\"temperature_2m_min\"] = daily_temperature_2m_min\n",
    "\n",
    "    # Ensuring weather API df and associated fire df are rightsized then combining\n",
    "    daily_dataframe = pd.DataFrame(data=daily_data)\n",
    "    df_fire_cleaned_repeat_day = pd.DataFrame(\n",
    "        np.tile(df_fire_cleaned.iloc[point].values, (len(daily_dataframe), 1)),\n",
    "        columns=df_fire_cleaned.columns,\n",
    "    )\n",
    "    daily_dataframe = pd.concat([daily_dataframe, df_fire_cleaned_repeat_day], axis=1)\n",
    "    daily_dataframe_agg = pd.concat(\n",
    "        [daily_dataframe_agg, daily_dataframe], ignore_index=True, axis=0\n",
    "    )\n",
    "\n",
    "# Getting random dates not associated with fires. Weather details will be\n",
    "# used for class 0 entries in the df - no fire ignited.\n",
    "generated_dates = rand_date(daily_dataframe_agg, 2000)\n",
    "extra_hourly_dataframe_agg = pd.DataFrame()\n",
    "extra_daily_dataframe_agg = pd.DataFrame()\n",
    "\n",
    "for point in tqdm(range(len(generated_dates))):\n",
    "    lat_long_modulo = point % len(df_fire_cleaned)\n",
    "    lat_current = df_fire_cleaned[\"Lat_DD\"].iloc[lat_long_modulo]\n",
    "    long_current = df_fire_cleaned[\"Long_DD\"].iloc[lat_long_modulo]\n",
    "\n",
    "    # In this call, pass the randomly generated date to the start and end param\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": lat_current,\n",
    "        \"longitude\": long_current,\n",
    "        \"start_date\": datetime.strftime(generated_dates[point].date(), \"%Y-%m-%d\"),\n",
    "        \"end_date\": datetime.strftime(generated_dates[point].date(), \"%Y-%m-%d\"),\n",
    "        \"hourly\": [\n",
    "            \"soil_moisture_0_to_7cm\",\n",
    "            \"surface_pressure\",\n",
    "            \"dew_point_2m\",\n",
    "            \"apparent_temperature\",\n",
    "            \"precipitation\",\n",
    "        ],\n",
    "        \"daily\": [\n",
    "            \"wind_speed_10m_max\",\n",
    "            \"et0_fao_evapotranspiration\",\n",
    "            \"temperature_2m_max\",\n",
    "            \"temperature_2m_min\",\n",
    "        ],\n",
    "        \"temperature_unit\": \"fahrenheit\",\n",
    "        \"wind_speed_unit\": \"mph\",\n",
    "        \"precipitation_unit\": \"inch\",\n",
    "        \"timezone\": \"America/Los_Angeles\",\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "    response = responses[0]\n",
    "\n",
    "    hourly = response.Hourly()\n",
    "    hourly_soil_moisture_0_to_7cm = hourly.Variables(0).ValuesAsNumpy()\n",
    "    hourly_surface_pressure = hourly.Variables(1).ValuesAsNumpy()\n",
    "    hourly_dew_point_2m = hourly.Variables(2).ValuesAsNumpy()\n",
    "    hourly_apparent_temperature = hourly.Variables(3).ValuesAsNumpy()\n",
    "    hourly_precipitation = hourly.Variables(4).ValuesAsNumpy()\n",
    "\n",
    "    hourly_data = {\n",
    "        \"date\": pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True).replace(\n",
    "                hour=23, minute=59, second=59\n",
    "            ),\n",
    "            freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "            inclusive=\"left\",\n",
    "        )\n",
    "    }\n",
    "    hourly_data[\"soil_moisture_0_to_7cm\"] = hourly_soil_moisture_0_to_7cm[\n",
    "        : len(hourly_data[\"date\"])\n",
    "    ]\n",
    "    hourly_data[\"surface_pressure\"] = hourly_surface_pressure[\n",
    "        : len(hourly_data[\"date\"])\n",
    "    ]\n",
    "    hourly_data[\"dew_point_2m\"] = hourly_dew_point_2m[: len(hourly_data[\"date\"])]\n",
    "    hourly_data[\"apparent_temperature\"] = hourly_apparent_temperature[\n",
    "        : len(hourly_data[\"date\"])\n",
    "    ]\n",
    "    hourly_data[\"precipitation\"] = hourly_precipitation[: len(hourly_data[\"date\"])]\n",
    "\n",
    "    # No need to resize the weather API df since we are not combining with the fire data\n",
    "    extra_hourly_dataframe = pd.DataFrame(data=hourly_data)\n",
    "    extra_hourly_dataframe_agg = pd.concat(\n",
    "        [extra_hourly_dataframe_agg, extra_hourly_dataframe], ignore_index=True, axis=0\n",
    "    )\n",
    "\n",
    "    daily = response.Daily()\n",
    "    daily_wind_speed_10m_max = daily.Variables(0).ValuesAsNumpy()\n",
    "    daily_et0_fao_evapotranspiration = daily.Variables(1).ValuesAsNumpy()\n",
    "    daily_temperature_2m_max = daily.Variables(2).ValuesAsNumpy()\n",
    "    daily_temperature_2m_min = daily.Variables(3).ValuesAsNumpy()\n",
    "\n",
    "    daily_data = {\n",
    "        \"date\": pd.date_range(\n",
    "            start=pd.to_datetime(daily.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(daily.TimeEnd(), unit=\"s\", utc=True),\n",
    "            freq=pd.Timedelta(seconds=daily.Interval()),\n",
    "            inclusive=\"left\",\n",
    "        )\n",
    "    }\n",
    "    daily_data[\"wind_speed_10m_max\"] = daily_wind_speed_10m_max\n",
    "    daily_data[\"et0_fao_evapotranspiration\"] = daily_et0_fao_evapotranspiration\n",
    "    daily_data[\"temperature_2m_max\"] = daily_temperature_2m_max\n",
    "    daily_data[\"temperature_2m_min\"] = daily_temperature_2m_min\n",
    "\n",
    "    # No need to resize the weather API df since we are not combining with the fire data\n",
    "    extra_daily_dataframe = pd.DataFrame(data=daily_data)\n",
    "    extra_daily_dataframe_agg = pd.concat(\n",
    "        [extra_daily_dataframe_agg, extra_daily_dataframe], ignore_index=True, axis=0\n",
    "    )\n",
    "\n",
    "# Combining the fire-related df's and the non-fire-related df's\n",
    "hourly_dataframe_agg = pd.concat(\n",
    "    [hourly_dataframe_agg, extra_hourly_dataframe_agg], ignore_index=True, axis=0\n",
    ")\n",
    "daily_dataframe_agg = pd.concat(\n",
    "    [daily_dataframe_agg, extra_daily_dataframe_agg], ignore_index=True, axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversions and Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During these steps, final conversions and the ultimate goal of merging all data into a singular set are accomplished. This includes variable mappings, date conversions, aggregate groupings, and null value handling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing size class with numeric values - we consider all levels of\n",
    "# fire the same since this model is aimed at measuring ignition, not severity\n",
    "size_class_dict = {\"A\": 1, \"B\": 1, \"C\": 1, \"D\": 1, \"E\": 1, \"F\": 1}\n",
    "\n",
    "daily_dataframe_agg[\"Size_class\"] = daily_dataframe_agg[\"Size_class\"].map(\n",
    "    size_class_dict\n",
    ")\n",
    "hourly_dataframe_agg[\"Size_class\"] = hourly_dataframe_agg[\"Size_class\"].map(\n",
    "    size_class_dict\n",
    ")\n",
    "\n",
    "# Converting to UTC datetime\n",
    "daily_dataframe_agg[\"date\"] = daily_dataframe_agg[\"date\"].dt.tz_convert(\"UTC\")\n",
    "hourly_dataframe_agg[\"date\"] = hourly_dataframe_agg[\"date\"].dt.tz_convert(\"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column at the date level\n",
    "hourly_dataframe_agg[\"day\"] = hourly_dataframe_agg[\"date\"].dt.date\n",
    "\n",
    "# Dropping columns not used in the model for analysis\n",
    "hourly_dataframe_agg.drop(\n",
    "    [\n",
    "        \"FireYear\",\n",
    "        \"FireName\",\n",
    "        \"EstTotalAcres\",\n",
    "        \"Protected_Acres\",\n",
    "        \"HumanOrLightning\",\n",
    "        \"CauseBy\",\n",
    "        \"GeneralCause\",\n",
    "        \"SpecificCause\",\n",
    "        \"Lat_DD\",\n",
    "        \"Long_DD\",\n",
    "        \"Ign_DateTime\",\n",
    "        \"ReportDateTime\",\n",
    "        \"Discover_DateTime\",\n",
    "        \"Control_DateTime\",\n",
    "        \"CreationDate\",\n",
    "        \"ModifiedDate\",\n",
    "        \"date\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Records with no fire assocation have a null Size_class from previous dictionary mapping.\n",
    "# Converting to 0 to indicate no fire.\n",
    "hourly_dataframe_agg[\"Size_class\"] = hourly_dataframe_agg[\"Size_class\"].fillna(\n",
    "    value=0.0\n",
    ")\n",
    "\n",
    "# Aggregating the hourly data - all are averages except for precipitation, a sum.\n",
    "daily_addhourly_dataframe_agg = hourly_dataframe_agg.groupby(\n",
    "    [\"day\", \"Size_class\"],\n",
    "    as_index=False,\n",
    ").agg(\n",
    "    {\n",
    "        \"soil_moisture_0_to_7cm\": \"mean\",\n",
    "        \"surface_pressure\": \"mean\",\n",
    "        \"dew_point_2m\": \"mean\",\n",
    "        \"apparent_temperature\": \"mean\",\n",
    "        \"precipitation\": \"sum\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Adding a column at the date level\n",
    "# and dropping columns not used in the model for analysis\n",
    "daily_dataframe_agg[\"day\"] = daily_dataframe_agg[\"date\"].dt.date\n",
    "daily_dataframe_agg.drop(\n",
    "    [\n",
    "        \"FireYear\",\n",
    "        \"FireName\",\n",
    "        \"EstTotalAcres\",\n",
    "        \"Protected_Acres\",\n",
    "        \"HumanOrLightning\",\n",
    "        \"CauseBy\",\n",
    "        \"GeneralCause\",\n",
    "        \"SpecificCause\",\n",
    "        \"Lat_DD\",\n",
    "        \"Long_DD\",\n",
    "        \"Ign_DateTime\",\n",
    "        \"ReportDateTime\",\n",
    "        \"Discover_DateTime\",\n",
    "        \"Control_DateTime\",\n",
    "        \"CreationDate\",\n",
    "        \"ModifiedDate\",\n",
    "        \"date\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "daily_dataframe_agg[\"Size_class\"] = daily_dataframe_agg[\"Size_class\"].fillna(value=0.0)\n",
    "\n",
    "# Merging the aggregated hourly and the daily df's\n",
    "daily_dataframe_merged = daily_dataframe_agg.merge(\n",
    "    daily_addhourly_dataframe_agg, on=[\"day\", \"Size_class\"], how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an initial feel for feature importance, inspect the correlation of 'Size_class', which indicates fire ignition (class 1) or no fire ignition (class 0) with the weather features. This basic visualization can also act as a domain knowledge check against which features should be negatively correlated, positively correlated, and the associated strengths. Importantly, some of these features may have more prominent effects in combination, but this offers a great gut check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Visualization to compare size class correlations with numeric variables\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFire Indicator and Weather Feature Correlation Map\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(daily_dataframe_merged\u001b[38;5;241m.\u001b[39mcorr(numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualization to compare size class correlations with numeric variables\n",
    "plt.figure(figsize=(9, 8))\n",
    "plt.title(\"Fire Indicator and Weather Feature Correlation Map\")\n",
    "sns.heatmap(daily_dataframe_merged.corr(numeric_only=True), annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and test data are split and the model and grid search are initialized. Since this is a classification problem, f1 score was chosen to be the primary metric to validate against, as accuracy can be misleading when large discrepancies exist between precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing and training an ensemble model for classification. Precision &\n",
    "# Recall used to identify performance instead of pure accuracy.\n",
    "\n",
    "pd_X = daily_dataframe_merged.drop([\"Size_class\", \"day\"], axis=1)\n",
    "pd_y = daily_dataframe_merged[\"Size_class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(pd_X, pd_y, test_size=0.2)\n",
    "\n",
    "# GridSearch to optimize hyperparameters based on the f1 score\n",
    "param_grid_RFC = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_depth\": [3, 5, 10, None],\n",
    "    \"max_features\": [1, 3, 5, 7],\n",
    "    \"min_samples_leaf\": [1, 2, 3],\n",
    "    \"min_samples_split\": [2, 3],\n",
    "}\n",
    "\n",
    "# Instantiating model\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "# GridSearch over parameters - n_jobs = -1 to improve speed, and optimizing f1 score\n",
    "# instead of accuracy.\n",
    "grid_RFC = GridSearchCV(\n",
    "    estimator=RFC,\n",
    "    param_grid=param_grid_RFC,\n",
    "    verbose=0,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"f1_micro\",\n",
    ")\n",
    "grid_RFC.fit(X_train, y_train)\n",
    "grid_pred = grid_RFC.predict(X_test)\n",
    "\n",
    "print(\"The classification report below:\")\n",
    "print(classification_report(y_test, grid_pred), flush=True)\n",
    "print(\"\\n\")\n",
    "print(\"The best parameters for the GridSearch:\")\n",
    "print(grid_RFC.best_params_, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Data Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For context to choose test variables for prediction probabilities, reference the below distribution of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <th>soil_moisture_0_to_7cm</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>dew_point_2m</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3977.000000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>3977.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.421334</td>\n",
       "      <td>0.141472</td>\n",
       "      <td>68.216537</td>\n",
       "      <td>46.449547</td>\n",
       "      <td>0.269830</td>\n",
       "      <td>941.659790</td>\n",
       "      <td>41.812965</td>\n",
       "      <td>52.784058</td>\n",
       "      <td>0.074116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.268403</td>\n",
       "      <td>0.079726</td>\n",
       "      <td>17.167141</td>\n",
       "      <td>11.927896</td>\n",
       "      <td>0.113666</td>\n",
       "      <td>50.252338</td>\n",
       "      <td>10.087990</td>\n",
       "      <td>15.839882</td>\n",
       "      <td>0.199732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.803527</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>13.435701</td>\n",
       "      <td>-7.476700</td>\n",
       "      <td>0.025647</td>\n",
       "      <td>796.177063</td>\n",
       "      <td>-9.966947</td>\n",
       "      <td>-6.105032</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.267593</td>\n",
       "      <td>0.067087</td>\n",
       "      <td>54.709702</td>\n",
       "      <td>38.255901</td>\n",
       "      <td>0.170471</td>\n",
       "      <td>902.357788</td>\n",
       "      <td>36.301258</td>\n",
       "      <td>40.614986</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.908989</td>\n",
       "      <td>0.149076</td>\n",
       "      <td>69.871994</td>\n",
       "      <td>48.635597</td>\n",
       "      <td>0.256098</td>\n",
       "      <td>951.912903</td>\n",
       "      <td>43.709663</td>\n",
       "      <td>55.755890</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.875792</td>\n",
       "      <td>0.209720</td>\n",
       "      <td>82.226303</td>\n",
       "      <td>55.567398</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>983.691528</td>\n",
       "      <td>49.247864</td>\n",
       "      <td>65.537361</td>\n",
       "      <td>0.039370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35.178558</td>\n",
       "      <td>0.395277</td>\n",
       "      <td>114.089005</td>\n",
       "      <td>76.235001</td>\n",
       "      <td>0.513588</td>\n",
       "      <td>1031.407837</td>\n",
       "      <td>62.730713</td>\n",
       "      <td>95.243599</td>\n",
       "      <td>2.338583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wind_speed_10m_max  et0_fao_evapotranspiration  temperature_2m_max  \\\n",
       "count         3977.000000                 3977.000000         3977.000000   \n",
       "mean             8.421334                    0.141472           68.216537   \n",
       "std              3.268403                    0.079726           17.167141   \n",
       "min              1.803527                    0.005268           13.435701   \n",
       "25%              6.267593                    0.067087           54.709702   \n",
       "50%              7.908989                    0.149076           69.871994   \n",
       "75%              9.875792                    0.209720           82.226303   \n",
       "max             35.178558                    0.395277          114.089005   \n",
       "\n",
       "       temperature_2m_min  soil_moisture_0_to_7cm  surface_pressure  \\\n",
       "count         3977.000000             3977.000000       3977.000000   \n",
       "mean            46.449547                0.269830        941.659790   \n",
       "std             11.927896                0.113666         50.252338   \n",
       "min             -7.476700                0.025647        796.177063   \n",
       "25%             38.255901                0.170471        902.357788   \n",
       "50%             48.635597                0.256098        951.912903   \n",
       "75%             55.567398                0.366000        983.691528   \n",
       "max             76.235001                0.513588       1031.407837   \n",
       "\n",
       "       dew_point_2m  apparent_temperature  precipitation  \n",
       "count   3977.000000           3977.000000    3977.000000  \n",
       "mean      41.812965             52.784058       0.074116  \n",
       "std       10.087990             15.839882       0.199732  \n",
       "min       -9.966947             -6.105032       0.000000  \n",
       "25%       36.301258             40.614986       0.000000  \n",
       "50%       43.709663             55.755890       0.000000  \n",
       "75%       49.247864             65.537361       0.039370  \n",
       "max       62.730713             95.243599       2.338583  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_dataframe_merged.describe().drop([\"Size_class\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The models predicted probability of a fire starting (class 1) with the given values:  1.52 %\n"
     ]
    }
   ],
   "source": [
    "# Make feature declarations to test model prediction probabilities - the below\n",
    "# selections are based on a 'best case' scenario, where weather conditions are\n",
    "# not favorable to a fire\n",
    "\n",
    "var_wind_speed = 5\n",
    "var_evapotranspiration = 0.04\n",
    "var_temperature_max = 50\n",
    "var_temperature_min = 20\n",
    "var_soil_moisture = 0.4\n",
    "var_surface_pressure = 800\n",
    "var_dew_point = 30\n",
    "var_apparent_temperature = 30\n",
    "var_precipitation = 0.01\n",
    "\n",
    "# Creating a dataframe to pass to the model\n",
    "new_weather_data = pd.DataFrame(\n",
    "    data=[\n",
    "        [\n",
    "            var_evapotranspiration,\n",
    "            var_evapotranspiration,\n",
    "            var_temperature_max,\n",
    "            var_temperature_min,\n",
    "            var_soil_moisture,\n",
    "            var_surface_pressure,\n",
    "            var_dew_point,\n",
    "            var_apparent_temperature,\n",
    "            var_precipitation,\n",
    "        ]\n",
    "    ],\n",
    "    columns=X_test.columns,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The models predicted probability of a fire starting (class {int(grid_RFC.classes_[1])}) with the given values: \",\n",
    "    round(grid_RFC.predict_proba(new_weather_data)[0][1] * 100, 2),\n",
    "    \"%\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
